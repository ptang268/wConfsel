{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37507e5c-8507-494e-a0a1-cd263d596f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.317\n",
      "Model:                            WLS   Adj. R-squared:                  0.316\n",
      "Method:                 Least Squares   F-statistic:                     1235.\n",
      "Date:                Tue, 19 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:08:50   Log-Likelihood:                -3979.4\n",
      "No. Observations:                8000   AIC:                             7967.\n",
      "Df Residuals:                    7996   BIC:                             7995.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0137      0.005      2.519      0.012       0.003       0.024\n",
      "x1            -0.9027      0.016    -55.157      0.000      -0.935      -0.871\n",
      "x2            -0.1139      0.018     -6.281      0.000      -0.149      -0.078\n",
      "x3             0.8454      0.025     33.762      0.000       0.796       0.894\n",
      "==============================================================================\n",
      "Omnibus:                     3456.492   Durbin-Watson:                   2.019\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           348417.810\n",
      "Skew:                          -1.119   Prob(JB):                         0.00\n",
      "Kurtosis:                      35.253   Cond. No.                         10.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ConfSelect import weighted_BH, weighted_CS, eval_sel\n",
    "q=0.5\n",
    "quantile = 0.9\n",
    "\n",
    "seed = 8\n",
    "\n",
    "# Step 1: Generate samples\n",
    "np.random.seed(seed)  # For reproducibility\n",
    "X1 = np.random.normal(0, 0.3, 16000)\n",
    "X2 = np.random.normal(0.5, 0.5, 1000)\n",
    "\n",
    "# Step 2: Combine X1 and X2, generate Y\n",
    "X = np.concatenate((X1, X2))\n",
    "e = np.random.normal(0, 0.3, X.shape[0])\n",
    "Y = - X + X**3 + e\n",
    "\n",
    "# Preparing the data for regression (adding X^2 and X^3)\n",
    "X_poly = np.vstack([X, X**2, X**3]).T\n",
    "\n",
    "# Assuming you have a logic for assigning weights\n",
    "# Here's an example of creating weights (this should be adapted to your actual use case)\n",
    "# For simplicity, we'll create weights inversely proportional to the standard deviation of each segment\n",
    "# This is a placeholder and should be replaced with your specific weighting logic\n",
    "weights = np.exp((X_poly[:, 0]+0.28)**2/(2*0.375*0.375))\n",
    "#weights = weights / np.sum(weights)\n",
    "\n",
    "# Add a constant to the model\n",
    "X_poly_with_const = sm.add_constant(X_poly)\n",
    "\n",
    "# Split your data to match the original OLS setup\n",
    "X_train = X_poly_with_const[:8000]\n",
    "Y_train = Y[:8000]\n",
    "weights_train = weights[:8000]/np.sum(weights[:8000])\n",
    "\n",
    "# Fit the WLS model\n",
    "model = sm.WLS(Y_train, X_train, weights=weights_train).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3681a800-6d79-402c-a72e-73564dfea89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcalib = X_poly_with_const[8000:16000]\n",
    "dtest = X_poly_with_const[16000:]\n",
    "\n",
    "dother = np.concatenate((dcalib,dtest))\n",
    "all_pred = model.predict(dother)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "\n",
    "hat_mu_calib = np.array(model.predict(dcalib))\n",
    "hat_mu_test = np.array(model.predict(dtest))\n",
    "y_calib = Y[8000:16000]\n",
    "w_calib = weights[8000:16000]\n",
    "y_test = Y[16000:]\n",
    "w_test = weights[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169a6ad4-3620-4603-88dd-4723b0c52a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1261641407465864\n",
      "R^2 Score: 0.7503247419593937\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "mse = np.mean((y_test - hat_mu_test) ** 2)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R^2 Score\n",
    "y_mean = np.mean(y_test)\n",
    "ss_tot = np.sum((y_test - y_mean) ** 2)\n",
    "ss_res = np.sum((y_test - hat_mu_test) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5d6d97-a68d-4fe1-9a51-de6836fb4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[:8000]\n",
    "\n",
    "\n",
    "#c = 0\n",
    "c = np.quantile(y_train, quantile) \n",
    "\n",
    " \n",
    "calib_scores_res = y_calib - hat_mu_calib\n",
    "calib_scores_sub = - hat_mu_calib \n",
    "calib_scores_clip = 100 * (y_calib > c) + c * (y_calib <= c) - hat_mu_calib\n",
    " \n",
    "test_scores = c - hat_mu_test\n",
    "\n",
    " \n",
    "# ========================= \n",
    "# ## weighted BH procedure\n",
    "# ========================= \n",
    "\n",
    "# use scores res, sub, and clip\n",
    "BH_res = weighted_BH(calib_scores_res, w_calib, test_scores, w_test, q)  \n",
    "BH_sub = weighted_BH(calib_scores_sub[y_calib <= c], w_calib[y_calib<=c], test_scores, w_test, q) \n",
    "BH_clip = weighted_BH(calib_scores_clip, w_calib, test_scores, w_test, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408ba4f7-a5f4-4b1c-a324-670881b21161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FDP  power  nsel  ndiff  nsame score method    q  seed\n",
      "0    0      0     0      0      0   res    WBH  0.5     8\n",
      "1    0      0     0      0      0   sub    WBH  0.5     8\n",
      "2    0      0     0      0      0  clip    WBH  0.5     8\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# # summarize FDP, power and selection sizes\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "#BH_res_fdp, BH_res_power = eval_sel(BH_res, y_test, np.array([c]*len(y_test)))\n",
    "#BH_sub_fdp, BH_sub_power = eval_sel(BH_sub, y_test, np.array([c]*len(y_test)))\n",
    "#BH_clip_fdp, BH_clip_power = eval_sel(BH_clip, y_test, np.array([c]*len(y_test))) \n",
    "\n",
    "# Assuming BH_res[0] contains the integer indices you want to use for evaluation\n",
    "BH_res_indices = BH_res[0]\n",
    "# Now pass these indices to the eval_sel function\n",
    "BH_res_fdp, BH_res_power = eval_sel(BH_res_indices, y_test, np.array([c]*len(y_test)))\n",
    "\n",
    "# Assuming BH_sub[0] contains the integer indices for the \"sub\" case\n",
    "BH_sub_indices = BH_sub[0]\n",
    "# Now pass these indices to the eval_sel function\n",
    "BH_sub_fdp, BH_sub_power = eval_sel(BH_sub_indices, y_test, np.array([c]*len(y_test)))\n",
    "\n",
    "# Assuming BH_clip[0] contains the integer indices for the \"clip\" case\n",
    "BH_clip_indices = BH_clip[0]\n",
    "# Now pass these indices to the eval_sel function\n",
    "BH_clip_fdp, BH_clip_power = eval_sel(BH_clip_indices, y_test, np.array([c]*len(y_test)))\n",
    "\n",
    "\n",
    "# Organize BH results for DataFrame\n",
    "fdp = [BH_res_fdp, BH_sub_fdp, BH_clip_fdp]\n",
    "power = [BH_res_power, BH_sub_power, BH_clip_power]\n",
    "nsel = [len(BH_res_indices), len(BH_sub_indices), len(BH_clip_indices)]\n",
    "ndiff = [0] * 3  # Assuming no difference for BH-only results\n",
    "nsame = [len(BH_res_indices), len(BH_sub_indices), len(BH_clip_indices)]  # Assuming all selections are the same for BH-only results\n",
    "\n",
    "# Create DataFrame for BH-only results\n",
    "res_BH_only = pd.DataFrame({\n",
    "    \"FDP\": fdp,\n",
    "    \"power\": power,\n",
    "    \"nsel\": nsel,\n",
    "    \"ndiff\": ndiff,\n",
    "    \"nsame\": nsame,\n",
    "    \"score\": [\"res\", \"sub\", \"clip\"],\n",
    "    \"method\": [\"WBH\"] * 3,\n",
    "    \"q\": q,\n",
    "    \"seed\": seed\n",
    "})\n",
    "\n",
    "# If you want to print or use res_BH_only DataFrame\n",
    "print(res_BH_only)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
